% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ICLeastSquaresClassifier.R
\name{ICLeastSquaresClassifier}
\alias{ICLeastSquaresClassifier}
\title{Implicitly Constained Least Squares Classifier}
\usage{
ICLeastSquaresClassifier(X, y, X_u = NULL, lambda1 = 0, lambda2 = 0,
  intercept = TRUE, x_center = FALSE, scale = FALSE, method = "LBFGS",
  projection = "supervised", lambda_prior = 0, trueprob = NULL,
  eps = 1e-09, y_scale = FALSE, use_Xu_for_scaling = TRUE)
}
\arguments{
\item{X}{Design matrix, intercept term is added within the function}

\item{y}{Vector or factor with class assignments}

\item{X_u}{Design matrix of the unlabeled data, intercept term is added within the function}

\item{lambda1}{Regularization parameter in the unlabeled+labeled data regularized least squares}

\item{lambda2}{Regularization parameter in the labeled data only regularized least squares}

\item{intercept}{TRUE if an intercept should be added to the model}

\item{x_center}{logical; Whether the feature vectors should be centered}

\item{scale}{logical; If TRUE, apply a z-transform to all observations in X and X_u before running the regression}

\item{method}{Either "LBFGS" for solving using L-BFGS-B gradient descent or "QP" for a quadratic programming based solution}

\item{projection}{One of "supervised", "semisupervised" or "euclidean"}

\item{lambda_prior}{numeric; prior on the deviation from the supervised mean y}

\item{trueprob}{numeric; true mean y for all data}

\item{eps}{numeric; Stopping criterion for the maximinimization}

\item{y_scale}{logical; whether the target vector should be centered}

\item{use_Xu_for_scaling}{logical; whether the unlabeled objects should be used to determine the mean and scaling for the normalization}

\item{...}{additional arguments}
}
\value{
S4 object of class ICLeastSquaresClassifier with the following slots:
\item{theta}{weight vector}
\item{classnames}{the names of the classes}
\item{modelform}{formula object of the model used in regression}
\item{scaling}{a scaling object containing the paramters of the z-transforms applied to the data}
\item{optimization}{the object returned by the optim function}
\item{unlabels}{the labels assigned to the unlabeled objects}
}
\description{
Implicitly constrained semisupervised learning with quadratic loss. Least squares regression is used treating classes as targets (1 for one class, 2 for the other). We find an (fractional) labelling of the unlabeled objects, whose least squares regression solution minimizes the least squares loss on the labeled training data only. This is equivalent to finding a weighting of the unlabeled objects belonging to either of the two classes.
}
\examples{
data(testdata)
w1 <- LeastSquaresClassifier(testdata$X, testdata$y, 
                             intercept = TRUE,x_center = FALSE, scale=FALSE)
w2 <- ICLeastSquaresClassifier(testdata$X, testdata$y, 
                               testdata$X_u, intercept = TRUE, x_center = FALSE, scale=FALSE)
plot(testdata$X[,1],testdata$X[,2],col=factor(testdata$y),asp=1)
points(testdata$X_u[,1],testdata$X_u[,2],col="darkgrey",pch=16,cex=0.5)

abline(line_coefficients(w1)$intercept,
       line_coefficients(w1)$slope,lty=2)
abline(line_coefficients(w2)$intercept,
       line_coefficients(w2)$slope,lty=1)
}
\references{
Krijthe, J.H. & Loog, M., 2015. Implicitly Constrained Semi-Supervised Least Squares Classification. In E. Fromont, T. De Bie, & M. van Leeuwen, eds. 14th International Symposium on Advances in Intelligent Data Analysis XIV (Lecture Notes in Computer Science Volume 9385). Saint Etienne. France, pp. 158-169.
}
\seealso{
Other RSSL LeastSquares: \code{\link{EMLeastSquaresClassifier}}
}

