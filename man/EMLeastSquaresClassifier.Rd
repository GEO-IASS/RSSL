% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/EMLeastSquaresClassifier.R
\name{EMLeastSquaresClassifier}
\alias{EMLeastSquaresClassifier}
\title{An Expectation Maximization like approach to Semi-Supervised Least Squares Classification}
\usage{
EMLeastSquaresClassifier(X, y, X_u, method = "inverse", x_center = FALSE,
  scale = FALSE, verbose = FALSE, intercept = TRUE, lambda = 0,
  eps = 1e-09)
}
\arguments{
\item{X}{design matrix of the labeled objects}

\item{y}{vector with labels}

\item{X_u}{design matrix of the labeled objects}

\item{method}{character; Currently only "EM"}

\item{scale}{Should the features be normalized? (default: FALSE)}

\item{verbose}{logical; Controls the verbosity of the output}

\item{eps}{Stopping criterion for the maximinimization}

\item{...}{Additional Parameters, Not used}
}
\description{
Minimize the total loss of the labeled and unlabeled objects by finding the weight vector and labels that minimize the total loss. The algorithm proceeds similar to EM, by subsequently applying a weight update and a soft labeling of the unlabeled objects. This is repeated until convergence.
}

