print.LearningCurve <- function(x) {
  cat("Learning Curve object\n\n")
  cat(names(x$results)[[2]],": ",paste(unique(x$results[[2]]),collapse=", "), "\n")
  cat("Classifiers:\n", paste("\t",levels(x$results$Classifier),collapse="\n"), "\n")
  cat("Measures:\n",  paste("\t",levels(x$results$Measure),collapse="\n"), "\n")
  cat(length(unique(x$results$repeats)), " repeats\n")
  cat(sum(is.na(x$results)), " missing\n")
}

#' Generate Learning Curve for a set of RSSL classifiers.
#'
#' \code{LearningCurve} runs learning curve experiments for a given dataset and set of classifiers
#'
#' This function generates the supervised learning curve for one or several classifiers. The learning curve is generated by increasing the number of training points used to train the classifier and evaluating performance.
#' 
#' @param X design matrix of the labeled objects
#' @param y vector with labels
#' @param classifiers list; Classifiers to crossvalidate
#' @param with_replacement logical; Whether objects should be drawn with replacement
#' @param sizes integer vector; sizes of the training sets
#' @param n_test integer; number of test objects to be drawn (only when with_replacement==TRUE)
#' @param repeats integer; Number of learning curves to average over
#' @param verbose logical; Controls verbosity of the output
#' 
#' @return A list with the following items:
#' 
#' @family RSSL evaluation
#' 
#' @export
LearningCurve.matrix <- function(X, y, classifiers, with_replacement=FALSE, sizes=seq(10,nrow(X),10), n_test=1000, repeats=100, verbose=TRUE) {
  
  results<-array(NA, dim=c(repeats, length(sizes), length(classifiers), 4))
  if (is.null(names(classifiers))) {
    classifier_names <- lapply(classifiers, function(c) {as.character(body(c))[[2]]})
  } else {
    classifier_names <- names(classifiers) 
  }
  
  dimnames(results)<-list(1:repeats, sizes, classifier_names, c("Error", "Loss Test", "Loss Train"))
  
  sample.test<-sample(1:nrow(X), n_test, replace=TRUE)
  X_test<-X[sample.test,,drop=FALSE]
  y_test<-y[sample.test]
  
  if (verbose) cat("Number of features: ",ncol(X),"\n")
  if (verbose) cat("Number of objects:  ",nrow(X),"\n")
  if (verbose) pb<-txtProgressBar(0,repeats) # Display a text progress bar
  
  for (i in 1:repeats) {
    if (verbose) setTxtProgressBar(pb, i) # Print the current repeat
    
    sample.labeled<- sample_k_per_level(y,1)
    if (with_replacement) {
      sample.labeled<-c(sample.labeled, sample(1:nrow(X),max(sizes)-2,replace=TRUE))
    } else {
      stop("Without replacement not implemented yet.")
    }
    
    X_l<-X[sample.labeled,,drop=FALSE]
    y_l<-y[sample.labeled]
    
    for (s in 1:length(sizes)) {
      X_l_s <- X_l[1:sizes[s],,drop=FALSE]
      y_l_s <- y_l[1:sizes[s]]
      for (c in 1:length(classifiers)) {
        try({
          trained_classifier<-do.call(classifiers[[c]],list(X_l_s, y_l_s, X_u=NULL,y_u=NULL))        
          results[i,s,c,1] <- 1-mean(y_test==predict(trained_classifier,X_test))
          results[i,s,c,2] <- sum(loss(trained_classifier, X_test, y_test))
          results[i,s,c,3] <- sum(loss(trained_classifier, X_l_s, y_l_s))
          results[i,s,c,4] <- sum(loss(trained_classifier, X_l_s, y_l_s))
        })
      }
    }
  }
  if (verbose) cat("\n")
  return(list(call="Not known",results=results,n_test=n_test,independent="Number of training objects"))
}

#' Generate Semi-Supervised learning curve.
#' 
#' Evaluate semi-supervised classifiers for different amounts of unlabeled training examples or different fractions of unlabeled vs. labeled examples.
#' 
#' @param X design matrix
#' @param y vector of labels
#' @param ... arguments passed to underlying function
#' 
#' @return LearningCurve object
#' 
#' @examples
#' X <- model.matrix(Species~.-1,data=iris)
#' y <- iris$Species
#' 
#' classifiers <- list("LS"=function(X,y,X_u,y_u) {LeastSquaresClassifier(X,y,lambda=0)}, 
#'                     "RLS"=function(X,y,X_u,y_u) {LeastSquaresClassifier(X,y,lambda=10)})
#' measures <- list("Accuracy" =  measure_accuracy,
#'                  "Loss" = measure_losstest,
#'                  "Loss labeled" = measure_losslab,
#'                  "Loss Lab+Unlab" = measure_losstrain
#'                  )
#' lc <- LearningCurveSSL(X,y,classifiers=classifiers,measures=measures,n_l=10,repeats=5)
#' print(lc)
#' plot(lc)
#' 
#' @export
LearningCurveSSL<-function(X, y, ...) {
  UseMethod("LearningCurveSSL")
}

#' @export
LearningCurveSSL.list<-function(X,y,...,verbose=FALSE,mc.cores=1) {

  if (is.matrix(X[[1]]) & is.factor(y[[1]])) {
    curves <- clapply(names(X),function(dname){
      if (verbose) cat(dname,"\n");
      
      Xd <- X[[dname]]
      Xd <- Xd[,colnames(Xd)!="(Intercept)"]
      Xd <- Xd[,apply(Xd, 2, var, na.rm=TRUE) != 0] # Remove constant columns
      yd <- y[[dname]]
      
      LearningCurveSSL(Xd,yd,...,verbose=verbose)
    },mc.cores=mc.cores)
  } else if (is(X[[1]],"formula") & is.data.frame(y[[1]])) { 
    curves <- clapply(names(X),function(dname){
      if (verbose) cat(dname,"\n");
      data <- data.frame(y[[dname]]) 
      classname <- all.vars(X[[dname]])[1]
      
      Xd <- model.matrix(X[[dname]],y[[dname]])
      Xd <- Xd[,colnames(Xd)!="(Intercept)"]
      Xd <- Xd[,apply(Xd, 2, var, na.rm=TRUE) != 0] # Remove constant columns
      yd <- data[,classname]
      
      LearningCurveSSL(Xd,yd,...,verbose=verbose)
    },mc.cores=mc.cores)
  } else {
    stop("Unknown input. Should be either a list of matrices and label vectors or formulae and data frames.")
  }
  names(curves) <- names(X)
  results <- dplyr::bind_rows(lapply(names(curves),function(x) {dplyr::mutate(curves[[x]]$results,Dataset=x)}))
  object<-list(n_l=curves[[1]]$n_l,
               results=results,
               n_test=curves[[1]]$n_test)
  class(object)<-"LearningCurve"
  return(object)
}

#' @rdname LearningCurveSSL
#' @param classifiers list; Classifiers to crossvalidate
#' @param n_l Number of labeled objects to be used in the experiments
#' @param with_replacement Indicated whether the subsampling is done with replacement or not (default: FALSE)
#' @param sizes vector with number of unlabeled objects for which to evaluate performance
#' @param n_test Number of test points if with_replacement is TRUE
#' @param repeats Number of learning curves to draw
#' @param n_min Minimum number of labeled objects per class in
#' @param verbose Print progressbar during execution (default: FALSE)
#' @param dataset_name character; Name of the dataset
#' @param type Type of learning curve, either "unlabeled" or "fraction"
#' @param fracs list; fractions of labeled data to use
#' @param test_fraction numeric; If not NULL a fraction of the object will be left out to serve as the test set
#' @param pre_scale logical; Whether the features should be scaled before the dataset is used
#' @param pre_pca logical; Whether the features should be preprocessed using a PCA step
#' @param measures named list of functions giving the measures to be used
#' @param time logical; Whether execution time should be saved.
#' @export
LearningCurveSSL.matrix<-function(X, y, classifiers, measures=list("Accuracy"=measure_accuracy), type="unlabeled", n_l, with_replacement=FALSE, sizes=2^(1:8), n_test=1000,repeats=100, verbose=FALSE,n_min=1,dataset_name=NULL,test_fraction=NULL,fracs=seq(0.1,0.9,0.1),time=TRUE,pre_scale=FALSE, pre_pca=FALSE,...) {
  
  if (!is.factor(y)) { stop("Labels are not a factor.") }
  if (nrow(X)!=length(y)) { stop("Number of objects in X and y do not match.") }
  K <- length(levels(y))
  
  # Pre-processing
  if (pre_scale) X <- scale(X) # Pre-scale data
  
  if (pre_pca) {
    t_pca <- princomp(X)
    n_comp <- sum(cumsum(t_pca$sdev^2)/sum(t_pca$sdev^2)<0.99)
    n_comp <- n_comp #min(c(n_comp,floor(n_labeled/2)))
    X <- t_pca$scores[,1:n_comp]
  }
  
  if (n_l=="enough") { n_l <- max(ncol(X)+5,20) }
  else if (n_l=="d") { n_l <- ncol(X)+1 }
  else if (n_l=="2d") { n_l <- ncol(X)*2 }
  else {n_l<-n_l}
  
  # Set variables
  
  if (type=="fraction") { sizes <- fracs }
  
  results<-array(NA, dim=c(repeats, length(sizes), length(classifiers), length(measures)+time))
  if (is.null(names(classifiers))) {
    classifier_names <- lapply(classifiers, function(c) {as.character(body(c))[[2]]})
  } else {
    classifier_names <- names(classifiers) 
  }
  
  if (is.null(names(measures))) {
    measure_names <- lapply(measures, function(c) {as.character(body(c))[[2]]})
  } else {
    measure_names <- names(measures) 
  }
  
  if (time) { measure_names<-c(measure_names,"Time")}
  name_list <- list("repeats"=1:repeats,
                    "independent"=sizes,
                    "Classifier"=classifier_names,
                    "Measure"=measure_names
  )
  if (type=="fraction") {
    names(name_list)[[2]] <- "Fraction of labeled objects"
  } else {
    names(name_list)[[2]] <- "Number of unlabeled objects"
  }
  dimnames(results)<- name_list
  
  if (verbose) cat("Number of features: ", ncol(X),"\n")
  if (verbose) cat("Number of objects:  ", nrow(X),"\n")
  if (verbose) pb <- txtProgressBar(0,repeats) # Display a text progress bar
  
  if (type=="unlabeled") {
    for (i in 1:repeats) {
      if (verbose) setTxtProgressBar(pb, i) # Print the current repeat
      
      sample.labeled <- sample_k_per_level(y,n_min)
      sample.labeled <- c(sample.labeled, sample((1:nrow(X))[-sample.labeled],n_l-(K*n_min),replace=FALSE))
    
      X_l <- X[sample.labeled,,drop=FALSE]
      y_l <- y[sample.labeled]
      
      if (!with_replacement) {
        sample.unlabeled <- sample((1:nrow(X))[-sample.labeled])
      } else {
        sample.unlabeled <- sample(1:nrow(X),max(sizes)+n_test,replace=TRUE)
      }
      X_u <- X[sample.unlabeled,,drop=FALSE]
      y_u <- y[sample.unlabeled]
      
      for (s in 1:length(sizes)) {
        if (sizes[s]>nrow(X_u)) {break}
        
        X_u_s <- X_u[1:sizes[s],,drop=FALSE]
        y_u_s <- y_u[1:sizes[s]]
        if (!with_replacement) {
          X_test <- X_u[-(1:sizes[s]),,drop=FALSE]
          y_test <- y_u[-(1:sizes[s])]
        } else {
          X_test <- X_u[-(1:max(sizes)),,drop=FALSE]
          y_test <- y_u[-(1:max(sizes))]
        }
        
        for (c in 1:length(classifiers)) {
          if (time) timed <- proc.time()
            trained_classifier<-do.call(classifiers[[c]],
                                      list(X=X_l, y=y_l, X_u=X_u_s, y_u=y_u_s))
          if (time) {
            timed <- proc.time()-timed
            results[i,s,c,length(measures)+1] <- timed[[3]]  
          }
          for (m in 1:length(measures)) {
            results[i,s,c,m] <- do.call(measures[[m]],
                                        list(trained_classifier=trained_classifier,
                                             X=X_l, 
                                             y=y_l, 
                                             X_u=X_u_s, 
                                             y_u=y_u_s,
                                             X_test=X_test,
                                             y_test=y_test))
          }
        }
      }
    }
  } else if (type=="fraction") {
    for (i in 1:repeats) {
    sample.guaranteed <- sample_k_per_level(y,n_min)
    if (!is.null(test_fraction)) { 
      idx_test <- sample((1:nrow(X))[-sample.guaranteed], size=ceiling(nrow(X)*test_fraction))
      sampleorder <- c(sample.guaranteed,sample((1:nrow(X))[-c(sample.guaranteed,idx_test)]))
    } else {
      sampleorder <- c(sample.guaranteed,sample((1:nrow(X))[-c(sample.guaranteed)]))
    }
    
    for (s in 1:length(fracs)) {
      idx_lab <- sampleorder[1:ceiling(length(sampleorder)*fracs[s])]
      
      X_l <- X[idx_lab,,drop=FALSE]
      y_l <- y[idx_lab]
      if (!is.null(test_fraction)) {
        # Separate test set
        X_u <- X[-c(idx_lab,idx_test),,drop=FALSE]
        y_u <- y[-c(idx_lab,idx_test)]
        
        X_test <- X[idx_test,,drop=FALSE]
        y_test <- y[idx_test]
      } else {
        # Test on unlabeled data
        X_u <- X[-c(idx_lab),,drop=FALSE]
        y_u <- y[-c(idx_lab)]
        
        X_test <- X_u
        y_test <- y_u
      }
      
      for (c in 1:length(classifiers)) {
        if (time) timed <- proc.time()
        trained_classifier<-do.call(classifiers[[c]],
                                    list(X=X_l, y=y_l, X_u=X_u, y_u=y_u))
        if (time) {
          timed <- proc.time()-timed
          results[i,s,c,length(measures)+1] <- timed[[3]]  
        }
        
        for (m in 1:length(measures)) {
          results[i,s,c,m] <- do.call(measures[[m]],
                                      list(trained_classifier=trained_classifier,
                                           X=X_l, y=y_l, 
                                           X_u=X_u, y_u=y_u,
                                           X_test=X_test,y_test=y_test))
        }
      }
    }
    }
  } else {
    stop("Unknown value for argument 'type'")
  }
  if (verbose) cat("\n")
  
  object<-list(n_l=n_l,
               results=reshape2::melt(results),
               n_test=n_test)
  class(object)<-"LearningCurve"
  return(object)
}

#' Plot LearningCurve object
#' 
#' @param x LearningCurve object
#' @param y Not used
#' @param ... Not used
#' @method plot LearningCurve
#' @export
plot.LearningCurve <- function(x, y, ...) {
  
  data <- x
  
  # Check for input object
  if (class(data)=="LearningCurve") { 
    data <- list(data)
  } else if (!(is.list(data) & all(lapply(data,class)=="LearningCurve"))) {
    stop("Input object should be LearningCurve of list of LearningCurve objects.")
  }
  
  # Extract metadata from the first experiment
  #m<-measurement
  x_label <- paste0("`",names(x$results)[[2]],"`")
  #y_label <- dimnames(data[[1]]$results)[[4]][m]

  # Generate the dataset for plotting
  if ("Dataset" %in% names(x$results)) {
    plot_frame <-  x$results %>% 
      dplyr::group_by_(x_label, quote(Classifier), quote(Measure), quote(Dataset)) %>%
      summarize_(Mean=quote(mean(value,na.rm=TRUE)),SE=quote(sd(value,na.rm=TRUE)/sqrt(n()))) %>% 
      ungroup
    facet_used <- facet_wrap(~ Dataset + Measure,scales="free",ncol=length(unique(plot_frame$Measure)))
  } else {
    plot_frame <-  x$results %>% 
      dplyr::group_by_(x_label, quote(Classifier), quote(Measure)) %>%
      summarize_(Mean=quote(mean(value,na.rm=TRUE)),SE=quote(sd(value,na.rm=TRUE)/sqrt(n()))) %>% 
      ungroup
    facet_used <- facet_wrap(~Measure,scales="free")
  }
  
  p <- plot_frame %>% 
    ggplot(aes_string(x=x_label,y="Mean",color="Classifier",shape="Classifier")) +
    geom_point(size=1) +
    geom_line(aes_string(linetype="Classifier")) +
    geom_ribbon(aes_string(ymax="Mean+1*SE",ymin="Mean-1*SE",fill="Classifier"),size=0,alpha=0.3,color=0) +
    #geom_errorbar(aes(ymax=Mean+2*SE,ymin=Mean-2*SE,fill=Classifier),width=0.1) +
    theme_classic() +
    facet_used +
    ylab("") +
    theme(legend.position="bottom",
          strip.background=element_rect(size = 0),
          axis.title.y=element_text(angle = 0,size=rel(0.8)),
          axis.title.x=element_text(size=rel(0.8)),
          axis.text.y=element_text(size=rel(0.8)),
          axis.text.x=element_text(size=rel(0.8)))
  if (x_label=="`Fraction of labeled objects`") {
    p <- p + scale_x_continuous()
  } else {
    p <- p + scale_x_continuous(trans = scales::log2_trans())
  }
  
  return(p)
}

#' Plot of difference between supervised and semi-supervised errors
#' 
#' @param data LearningCurve object
#' @param measurement Index of the measurement to be plotted
#' @param legendsetting Where the legend should be placed
#' @param dataset_names Names of the datasets in the LearningCurve object
#' @param classifier_names Names of the classifiers in the LearningCurve object
#' 
#' @export
DifferencePlot<-function(data,measurement=1,legendsetting="right",dataset_names=NULL,classifier_names=NULL) {
  
  # Check for input object
  if (class(data)=="LearningCurve") { 
    data <- list(data)
  } else if (!(is.list(data) & all(lapply(data,class)=="LearningCurve"))) {
    stop("Input object should be LearningCurve of list of LearningCurve objects.")
  }
  
  # Extract metadata from the first experiment
  m<-measurement
  x_label <- data[[1]]$independent
  y_label <- dimnames(data[[1]]$results)[[4]][m]
  
  # Generate the dataset for plotting
  dataframes.merged<-list()
  for (i in 1:length(data)) {
    data_i<-data[[i]]
    
    results<-data_i$results[,,,,drop=FALSE]
    
    classifiers.names<-dimnames(data_i$results)[[3]]
    sizes<-dimnames(data_i$results)[[2]]
    
    res_dif1 <- results[,1,1,m]-results[,1,2,m]
    res_dif2 <- results[,1,1,m]-results[,1,3,m]
#     res_dif3 <- results[,1,4,m]-results[,1,5,m]
    dataset_name <- ifelse(is.null(dataset_names),i,dataset_names[[i]])
    
#     dataframes.merged[[i]]<-fill(data.frame(res_dif=res_dif1,Dataset=dataset_name,Classifier="Projection"), data.frame(res_dif=res_dif2,Dataset=dataset_name,Classifier="Self Learning"), data.frame(res_dif=res_dif3,Dataset=dataset_name,Classifier="TSVM"))
dataframes.merged[[i]]<-data.table::rbindlist(data.frame(res_dif=res_dif1,Dataset=dataset_name,Classifier="Projection"), data.frame(res_dif=res_dif2,Dataset=dataset_name,Classifier="Self Learning"))
  }
  plotdata<-data.table::rbindlist(dataframes.merged)
  # Reorder and relabel the classifier names
#   if (!is.null(classifier_names)) {
#     plotdata$Classifier<-factor(plotdata$Classifier,levels=classifiers.names,labels=classifier_names)
#   } else {
#     plotdata$Classifier<-factor(plotdata$Classifier,levels=classifiers.names)
#   }
  
  h <- ggplot(plotdata, aes_string(x='Dataset',y='res_dif',color='Classifier',group='Classifier')) + geom_point(size=3) + facet_wrap(~ Classifier, ncol = 3, scales="free_y") + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position="none",axis.title.x = element_blank()) + ylab("Loss difference") + scale_y_continuous(limits = c(-1,1 )) + geom_hline(aes(yintercept=0))
  return(h)
}

#' Sample k indices per levels from a factor 
#' @param y factor; factor with levels
#' @param k integer; number of indices to sample per level
#' @return vector with indices for sample
#' @export
sample_k_per_level <- function(y,k) {
  stopifnot(is.factor(y))
  stopifnot(k>0)
  
  all_idx <- 1:length(y)
  sample_idx <- c()
  for (i in levels(y)) {
    sample_idx <- c(sample_idx,sample(all_idx[y==i],k))
  }
  return(sample_idx)
}
